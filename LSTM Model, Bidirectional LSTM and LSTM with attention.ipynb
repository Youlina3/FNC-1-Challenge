{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import plot_model \n",
    "from IPython.display import Image\n",
    "import pydot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "#from keras import initializations\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "tf_gpu_options = tf.GPUOptions(allow_growth = True) # per_process_gpu_memory_fraction=0.12,\n",
    "tf_session = tf.Session(config=tf.ConfigProto(gpu_options=tf_gpu_options))\n",
    "tf.keras.backend.set_session(tf_session)\n",
    "\n",
    "#biodirectional embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder locations\n",
    "#W2V_DIR = './data/GoogleNews-vectors-negative300.bin' #\n",
    "GloVe_DIR = './data/glove.twitter.27B.50d.txt'\n",
    "#the data directory\n",
    "DATA_DIR = './data'\n",
    "# These are some hyperparameters that can be tuned\n",
    "MAX_SENT_LEN = 150 #75(0.68), 150, 300 700(90% but too time comsuming)\n",
    "MAX_VOCAB_SIZE = 40000 #vocabulary\n",
    "LSTM_DIM = 100#len(embd[0])\n",
    "EMBEDDING_DIM = 50 #50 for GloVe 300 for w2v\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 40 #40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic latm(1):GoogleNews: 75 150(0.7158 for 1 epoch) 300 700||GloVe: 75 150(0.7162 for 1 epoch) 300 700\n",
    "bidrectional latm:GloVe: 75 150( 0.7141 for 1 epoch) 300 700\n",
    "Glove+LSTM+ATTENTION(kaddle): 0.7162 for 1 epoch\n",
    "Glove+LSTM+ATTENTION(attentionsize=15): 0.7162 for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text files of fnc data\n",
    "bodies = pd.read_csv(DATA_DIR + '/body_table.csv')\n",
    "    \n",
    "train_df = pd.read_csv(DATA_DIR + '/train_data.csv')\n",
    "\n",
    "#validation_df = pd.read_csv(DATA_DIR + '/validation_data.csv')\n",
    "\n",
    "test_df = pd.read_csv(DATA_DIR + '/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.replace('unrelated',1,True)\n",
    "train_df.replace('agree',2,True)\n",
    "train_df.replace('disagree',3,True)\n",
    "train_df.replace('discuss',4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df_train = train_df.join(bodies.set_index('Body ID'), on='Body ID')\n",
    "combine_df_test = test_df.join(bodies.set_index('Body ID'), on='Body ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing involves removal of puctuations and converting text to lower case\n",
    "word_seq_head_train = [text_to_word_sequence(head) for head in combine_df_train['Headline']]\n",
    "word_seq_bodies_train = [text_to_word_sequence(body) for body in combine_df_train['articleBody']]\n",
    "word_seq_head_test = [text_to_word_sequence(head) for head in combine_df_test['Headline']]\n",
    "word_seq_bodies_test = [text_to_word_sequence(body) for body in combine_df_test['articleBody']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th Percentile Sentence of headline: 16.0\n"
     ]
    }
   ],
   "source": [
    "print('90th Percentile Sentence of headline:', np.percentile([len(seq) for seq in word_seq_head_train], 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th Percentile Sentence of body: 306.0\n"
     ]
    }
   ],
   "source": [
    "print('90th Percentile Sentence of body:', np.percentile([len(seq) for seq in word_seq_bodies_train], 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_seq = []\n",
    "for i in range(len(word_seq_head_train)):\n",
    "    word_seq.append(word_seq_head_train[i])\n",
    "for i in range(len(word_seq_bodies_train)):\n",
    "    word_seq.append(word_seq_bodies_train[i])\n",
    "for i in range(len(word_seq_head_test)):\n",
    "    word_seq.append(word_seq_head_test[i])\n",
    "for i in range(len(word_seq_bodies_test)):\n",
    "    word_seq.append(word_seq_bodies_test[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocabulary: 35375\n"
     ]
    }
   ],
   "source": [
    "filter_list = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters=filter_list)\n",
    "tokenizer.fit_on_texts([seq for seq in word_seq])\n",
    "##because it only includes unique words(tokens)\n",
    "\n",
    "print(\"Number of words in vocabulary:\", len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine headline and body together\n",
    "word_seq_train = [list(i) for i in word_seq_head_train]\n",
    "for i in range(len(word_seq_head_train)):\n",
    "    word_seq_train[i].extend(word_seq_bodies_train[i]) \n",
    "    \n",
    "word_seq_test = [list(i) for i in word_seq_head_test]\n",
    "for i in range(len(word_seq_head_test)):\n",
    "    word_seq_test[i].extend(word_seq_bodies_test[i]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorten the sentence to a fixed length\n",
    "# Convert the sequence of words to sequnce of indices\n",
    "X_train = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_train])\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "y_train = combine_df_train['Stance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sequence of words to sequnce of indices\n",
    "X_test = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_test])\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SENT_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder_train = LabelEncoder()\n",
    "encoder_train.fit(y_train)\n",
    "encoded_train = encoder_train.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vali, y_train, y_vali = train_test_split(X_train, dummy_y_train, random_state=10, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W2V_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4a754a6fe0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the word2vec embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2V_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'W2V_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the word2vec embeddings \n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format(W2V_DIR, binary=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GloVes Load\n",
    "glove_input_file = GloVe_DIR\n",
    "word2vec_output_file = 'glove.50d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding matrix containing only the word's in our vocabulary\n",
    "# If the word does not have a pre-trained embedding, then randomly initialize the embedding\n",
    "embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, EMBEDDING_DIM)) # +1 is because the matrix indices start with 0\n",
    "for word, i in tokenizer.word_index.items(): # i=0 is the embedding for the zero padding\n",
    "    try:\n",
    "        embeddings_vector = embeddings[word]\n",
    "    except KeyError:\n",
    "        embeddings_vector = None\n",
    "        #word 是sentence里的\n",
    "        #none: if sentence里的word没有对应的pre-trained embedding 那么就有keyerror了\n",
    "    if embeddings_vector is not None:\n",
    "        embeddings_matrix[i] = embeddings_vector\n",
    "        #如果存在pre-trained word embedding，那么把这个embedding给到embedding_matrix里\n",
    "        #embeddings_matrix的第i行对应Wi\n",
    "        \n",
    "del embeddings\n",
    "#delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a sequential model by stacking neural net units \n",
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embeddings_matrix], trainable=True, name='word_embedding_layer', #False\n",
    "                          mask_zero=True))\n",
    "#mask_zero is to deal with padding problem\n",
    "#model.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='lstm_layer1'))) #bi(lstm)\n",
    "model_1.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='Bidrectional_lstm_layer1')))\n",
    "model_1.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.2\n",
    "model_1.add(Dense(4, activation='softmax', name='output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_1, to_file='bidirectional_model.png', show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"./result/lstm/epoch40/Bidirectional_lstm_150token_lr0.001_trainable_{epoch:02d}_{val_acc:.4f}.h5\"\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, \n",
    "                                       monitor='val_acc', \n",
    "                                       verbose=0, \n",
    "                                       save_best_only=True)\n",
    "\n",
    "callbacks_list1 = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before trainning model, we need to compile it\n",
    "#use adam optimizer\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60009 samples, validate on 6668 samples\n",
      "Epoch 1/40\n",
      "60009/60009 [==============================] - 177s 3ms/step - loss: 0.7869 - acc: 0.7258 - val_loss: 0.6607 - val_acc: 0.7629\n",
      "Epoch 2/40\n",
      "60009/60009 [==============================] - 179s 3ms/step - loss: 0.5995 - acc: 0.7796 - val_loss: 0.4960 - val_acc: 0.8134\n",
      "Epoch 3/40\n",
      "60009/60009 [==============================] - 205s 3ms/step - loss: 0.4726 - acc: 0.8236 - val_loss: 0.4283 - val_acc: 0.8410\n",
      "Epoch 4/40\n",
      "60009/60009 [==============================] - 255s 4ms/step - loss: 0.3872 - acc: 0.8553 - val_loss: 0.3638 - val_acc: 0.8634\n",
      "Epoch 5/40\n",
      "60009/60009 [==============================] - 250s 4ms/step - loss: 0.3262 - acc: 0.8747 - val_loss: 0.3183 - val_acc: 0.8763\n",
      "Epoch 6/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.2755 - acc: 0.8948 - val_loss: 0.2759 - val_acc: 0.8931\n",
      "Epoch 7/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.2352 - acc: 0.9079 - val_loss: 0.2604 - val_acc: 0.9000\n",
      "Epoch 8/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.2041 - acc: 0.9211 - val_loss: 0.2330 - val_acc: 0.9079\n",
      "Epoch 9/40\n",
      "60009/60009 [==============================] - 251s 4ms/step - loss: 0.1728 - acc: 0.9343 - val_loss: 0.2347 - val_acc: 0.9090\n",
      "Epoch 10/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.1511 - acc: 0.9421 - val_loss: 0.2157 - val_acc: 0.9220\n",
      "Epoch 11/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.1344 - acc: 0.9495 - val_loss: 0.2151 - val_acc: 0.9253\n",
      "Epoch 12/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.1179 - acc: 0.9550 - val_loss: 0.2376 - val_acc: 0.9214\n",
      "Epoch 13/40\n",
      "60009/60009 [==============================] - 253s 4ms/step - loss: 0.1035 - acc: 0.9611 - val_loss: 0.1988 - val_acc: 0.9298\n",
      "Epoch 14/40\n",
      "60009/60009 [==============================] - 250s 4ms/step - loss: 0.0950 - acc: 0.9647 - val_loss: 0.2026 - val_acc: 0.9343\n",
      "Epoch 15/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.0878 - acc: 0.9669 - val_loss: 0.2200 - val_acc: 0.9325\n",
      "Epoch 16/40\n",
      "60009/60009 [==============================] - 247s 4ms/step - loss: 0.0788 - acc: 0.9705 - val_loss: 0.2096 - val_acc: 0.9363\n",
      "Epoch 17/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.0734 - acc: 0.9729 - val_loss: 0.2203 - val_acc: 0.9379\n",
      "Epoch 18/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0660 - acc: 0.9761 - val_loss: 0.2185 - val_acc: 0.9352\n",
      "Epoch 19/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0649 - acc: 0.9759 - val_loss: 0.2121 - val_acc: 0.9396\n",
      "Epoch 20/40\n",
      "60009/60009 [==============================] - 250s 4ms/step - loss: 0.0569 - acc: 0.9789 - val_loss: 0.2166 - val_acc: 0.9444\n",
      "Epoch 21/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.0557 - acc: 0.9798 - val_loss: 0.2198 - val_acc: 0.9415\n",
      "Epoch 22/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.0497 - acc: 0.9811 - val_loss: 0.2125 - val_acc: 0.9418\n",
      "Epoch 23/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0459 - acc: 0.9832 - val_loss: 0.2170 - val_acc: 0.9433\n",
      "Epoch 24/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0461 - acc: 0.9832 - val_loss: 0.2199 - val_acc: 0.9427\n",
      "Epoch 25/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0410 - acc: 0.9854 - val_loss: 0.2225 - val_acc: 0.9471\n",
      "Epoch 26/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.0406 - acc: 0.9852 - val_loss: 0.2078 - val_acc: 0.9478\n",
      "Epoch 27/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.0368 - acc: 0.9867 - val_loss: 0.2342 - val_acc: 0.9487\n",
      "Epoch 28/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0361 - acc: 0.9873 - val_loss: 0.2366 - val_acc: 0.9439\n",
      "Epoch 29/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0347 - acc: 0.9882 - val_loss: 0.2405 - val_acc: 0.9483\n",
      "Epoch 30/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0331 - acc: 0.9884 - val_loss: 0.2325 - val_acc: 0.9468\n",
      "Epoch 31/40\n",
      "60009/60009 [==============================] - 249s 4ms/step - loss: 0.0318 - acc: 0.9890 - val_loss: 0.2420 - val_acc: 0.9468\n",
      "Epoch 32/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0292 - acc: 0.9898 - val_loss: 0.2386 - val_acc: 0.9525\n",
      "Epoch 33/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0312 - acc: 0.9901 - val_loss: 0.2395 - val_acc: 0.9490\n",
      "Epoch 34/40\n",
      "60009/60009 [==============================] - 248s 4ms/step - loss: 0.0285 - acc: 0.9904 - val_loss: 0.2427 - val_acc: 0.9522\n",
      "Epoch 35/40\n",
      "60009/60009 [==============================] - 214s 4ms/step - loss: 0.0247 - acc: 0.9914 - val_loss: 0.2484 - val_acc: 0.9496\n",
      "Epoch 36/40\n",
      "60009/60009 [==============================] - 167s 3ms/step - loss: 0.0265 - acc: 0.9913 - val_loss: 0.2620 - val_acc: 0.9498\n",
      "Epoch 37/40\n",
      "60009/60009 [==============================] - 179s 3ms/step - loss: 0.0233 - acc: 0.9922 - val_loss: 0.2400 - val_acc: 0.9504\n",
      "Epoch 38/40\n",
      "60009/60009 [==============================] - 185s 3ms/step - loss: 0.0195 - acc: 0.9934 - val_loss: 0.2427 - val_acc: 0.9502\n",
      "Epoch 39/40\n",
      "60009/60009 [==============================] - 181s 3ms/step - loss: 0.0226 - acc: 0.9925 - val_loss: 0.2502 - val_acc: 0.9535\n",
      "Epoch 40/40\n",
      "60009/60009 [==============================] - 187s 3ms/step - loss: 0.0227 - acc: 0.9924 - val_loss: 0.2350 - val_acc: 0.9516\n"
     ]
    }
   ],
   "source": [
    "#%%capture history\n",
    "#using different emedding pretrained dataset\n",
    "history_3 = model_1.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=N_EPOCHS,\n",
    "          validation_data=(X_vali, y_vali),callbacks = callbacks_list1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./history/history(bidirectional_lstm_epoch40_150_lr0.001_trainable)', 'wb') as file_pi:\n",
    "        pickle.dump(history_3.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy(Truncation: 150 Epoch: 10)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_state (?, 128)\n"
     ]
    }
   ],
   "source": [
    "model_file_path = './result/attention/epoch_40/FNC-1_LSTM_Attention_15Atlength_150_39_0.9318.h5'\n",
    "model = models.load_model(model_file_path,custom_objects = {'Attention': Attention()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6270"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [np.argmax(p, axis = -1) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(outputs)):\n",
    "    if outputs[i] == 0: outputs[i] = \"unrelated\"\n",
    "    if outputs[i] == 1: outputs[i] = \"disagree\"\n",
    "    if outputs[i] == 2: outputs[i] = \"agree\"\n",
    "    if outputs[i] == 3: outputs[i] = \"discuss\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = {}\n",
    "df_predicted = pd.DataFrame({'Stance': outputs})\n",
    "result = pd.concat([test_df, df_predicted], axis=1, sort=False)\n",
    "result.to_csv('./test_LSTM_Attention_split.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the model with and Batch-Normalization and Droupouts\n",
    "two more dense layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "word_embedding_layer (Embedd (None, None, 50)          1768800   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 1,829,604\n",
      "Trainable params: 60,804\n",
      "Non-trainable params: 1,768,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a sequential model by stacking neural net units \n",
    "#dense layer: simply a layer connect units \n",
    "#dropout layer: for reduce overfitting a regularization methhod\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embeddings_matrix], trainable=False, name='word_embedding_layer', \n",
    "                          mask_zero=True)) # trainable=True results in overfitting\n",
    "\n",
    "model.add(LSTM(LSTM_DIM, return_sequences=False, name='lstm_layer')) # Can try Bidirectional-LSTM\n",
    "\n",
    "#model.add(Dense(32, name='dense_1'))\n",
    "# model.add(BatchNormalization(name='bn_1')) # BN did not really help with performance \n",
    "model.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.2\n",
    "model.add(Activation(activation='relu', name='activation_1'))\n",
    "\n",
    "#model.add(Dense(8, name='dense_2'))\n",
    "# model.add(BatchNormalization(name='bn_2'))\n",
    "model.add(Dropout(rate=0.2, name='dropout_2'))\n",
    "model.add(Activation(activation='relu', name='activation_2'))\n",
    "\n",
    "model.add(Dense(4, activation='softmax', name='output_layer'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALLBACK FUCTION: TO SAVE MODEL FOR EVERY EPOCH END\n",
    "filepath=\"./saved_models/FNC-1_BASIC_LSTM_150_{epoch:02d}_{val_acc:.4f}.h5\"\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, \n",
    "                                       monitor='val_acc', \n",
    "                                       verbose=0, \n",
    "                                       save_best_only=True)\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60009 samples, validate on 6668 samples\n",
      "Epoch 1/40\n",
      "60009/60009 [==============================] - 92s 2ms/step - loss: 0.7785 - acc: 0.7263 - val_loss: 0.7134 - val_acc: 0.7308\n",
      "Epoch 2/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.7053 - acc: 0.7345 - val_loss: 0.6260 - val_acc: 0.7566\n",
      "Epoch 3/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.6452 - acc: 0.7481 - val_loss: 0.5710 - val_acc: 0.7774\n",
      "Epoch 4/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.5907 - acc: 0.7670 - val_loss: 0.5280 - val_acc: 0.7933\n",
      "Epoch 5/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.5737 - acc: 0.7754 - val_loss: 0.5436 - val_acc: 0.7828\n",
      "Epoch 6/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.5431 - acc: 0.7885 - val_loss: 0.5037 - val_acc: 0.8067\n",
      "Epoch 7/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.5051 - acc: 0.8032 - val_loss: 0.4731 - val_acc: 0.8097\n",
      "Epoch 8/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.4941 - acc: 0.8115 - val_loss: 0.4623 - val_acc: 0.8281\n",
      "Epoch 9/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.4604 - acc: 0.8255 - val_loss: 0.4381 - val_acc: 0.8319\n",
      "Epoch 10/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.4423 - acc: 0.8338 - val_loss: 0.4142 - val_acc: 0.8415\n",
      "Epoch 11/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.4239 - acc: 0.8431 - val_loss: 0.3844 - val_acc: 0.8524\n",
      "Epoch 12/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.4055 - acc: 0.8494 - val_loss: 0.3998 - val_acc: 0.8590\n",
      "Epoch 13/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3955 - acc: 0.8530 - val_loss: 0.3776 - val_acc: 0.8613\n",
      "Epoch 14/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3850 - acc: 0.8575 - val_loss: 0.3753 - val_acc: 0.8671\n",
      "Epoch 15/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3841 - acc: 0.8583 - val_loss: 0.3767 - val_acc: 0.8710\n",
      "Epoch 16/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3751 - acc: 0.8616 - val_loss: 0.3682 - val_acc: 0.8721\n",
      "Epoch 17/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3578 - acc: 0.8684 - val_loss: 0.3593 - val_acc: 0.8736\n",
      "Epoch 18/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3577 - acc: 0.8696 - val_loss: 0.3688 - val_acc: 0.8664\n",
      "Epoch 19/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3548 - acc: 0.8702 - val_loss: 0.3699 - val_acc: 0.8731\n",
      "Epoch 20/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3459 - acc: 0.8740 - val_loss: 0.3535 - val_acc: 0.8778\n",
      "Epoch 21/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3379 - acc: 0.8758 - val_loss: 0.3311 - val_acc: 0.8851\n",
      "Epoch 22/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3477 - acc: 0.8722 - val_loss: 0.4201 - val_acc: 0.8527\n",
      "Epoch 23/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3579 - acc: 0.8705 - val_loss: 0.3562 - val_acc: 0.8788\n",
      "Epoch 24/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3324 - acc: 0.8763 - val_loss: 0.3416 - val_acc: 0.8833\n",
      "Epoch 25/40\n",
      "60009/60009 [==============================] - 90s 1ms/step - loss: 0.3399 - acc: 0.8758 - val_loss: 0.3570 - val_acc: 0.8763\n",
      "Epoch 26/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3214 - acc: 0.8840 - val_loss: 0.3353 - val_acc: 0.8862\n",
      "Epoch 27/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3148 - acc: 0.8859 - val_loss: 0.3390 - val_acc: 0.8838\n",
      "Epoch 28/40\n",
      "60009/60009 [==============================] - 90s 1ms/step - loss: 0.3312 - acc: 0.8792 - val_loss: 0.3602 - val_acc: 0.8731\n",
      "Epoch 29/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3405 - acc: 0.8762 - val_loss: 0.3389 - val_acc: 0.8779\n",
      "Epoch 30/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3212 - acc: 0.8844 - val_loss: 0.3233 - val_acc: 0.8890\n",
      "Epoch 31/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3026 - acc: 0.8903 - val_loss: 0.3501 - val_acc: 0.8791\n",
      "Epoch 32/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3095 - acc: 0.8874 - val_loss: 0.3392 - val_acc: 0.8866\n",
      "Epoch 33/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3014 - acc: 0.8902 - val_loss: 0.3535 - val_acc: 0.8805\n",
      "Epoch 34/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3340 - acc: 0.8786 - val_loss: 0.3643 - val_acc: 0.8772\n",
      "Epoch 35/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3285 - acc: 0.8816 - val_loss: 0.3365 - val_acc: 0.8785\n",
      "Epoch 36/40\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.3180 - acc: 0.8837 - val_loss: 0.3321 - val_acc: 0.8814\n",
      "Epoch 37/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3020 - acc: 0.8902 - val_loss: 0.3150 - val_acc: 0.8892\n",
      "Epoch 38/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3036 - acc: 0.8903 - val_loss: 0.3375 - val_acc: 0.8869\n",
      "Epoch 39/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3151 - acc: 0.8873 - val_loss: 0.3540 - val_acc: 0.8857\n",
      "Epoch 40/40\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.3163 - acc: 0.8857 - val_loss: 0.3269 - val_acc: 0.8847\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../history/history(lstm_dropout+relu_epoch40_150_lr0.002_trainable)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9768a2a07f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_vali\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vali\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../history/history(lstm_dropout+relu_epoch40_150_lr0.002_trainable)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../history/history(lstm_dropout+relu_epoch40_150_lr0.002_trainable)'"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=N_EPOCHS,\n",
    "          validation_data=(X_vali, y_vali)\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./history/history(lstm_dropout+relu_epoch40_150_lr0.002_trainable)', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Saved Model to Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file_path = 'saved_models/FNC-1_BASIC_LSTM_150_0.7162.h5'\n",
    "model = models.load_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043/code\n",
    "#only attend first 15 states\n",
    "#I tried to combine the first 15states and last satates but I failed\n",
    "#I could not get to know the last cell state\n",
    "class Attention(Layer):\n",
    "    def __init__(self, attention_length = 20 ,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                  **kwargs):\n",
    "\n",
    "        #self.supports_masking = True\n",
    "        #Xavier uniform initializer\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "\n",
    "        self.attention_length = 30\n",
    "        self.features_dim = 100 \n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        \n",
    "        self.Wy = self.add_weight((self.features_dim,self.features_dim),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_Wy'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.Wh = self.add_weight((self.features_dim,self.features_dim),\n",
    "                                     initializer=self.init,\n",
    "                                     name='{}_Wh'.format(self.name),\n",
    "                                     regularizer=self.W_regularizer,\n",
    "                                     constraint=self.W_constraint)\n",
    "\n",
    "        self.w = self.add_weight((self.features_dim,1),\n",
    "                                     initializer=self.init,\n",
    "                                     name='{}_x'.format(self.name),\n",
    "                                     regularizer=self.W_regularizer,\n",
    "                                     constraint=self.W_constraint)\n",
    "\n",
    "        self.Wp = self.add_weight((self.features_dim,self.features_dim),\n",
    "                                     initializer=self.init,\n",
    "                                     name='{}_Wp'.format(self.name),\n",
    "                                     regularizer=self.W_regularizer,\n",
    "                                     constraint=self.W_constraint)\n",
    "        \n",
    "        self.Wx = self.add_weight((self.features_dim,self.features_dim),\n",
    "                                     initializer=self.init,\n",
    "                                     name='{}_Wx'.format(self.name),\n",
    "                                     regularizer=self.W_regularizer,\n",
    "                                     constraint=self.W_constraint)\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        \n",
    "        Y_states = tf.slice(x, begin = [0, 0, 0], size = [-1, self.attention_length, -1]) #15 first states\n",
    "        h_state = x[:,-1,:]\n",
    "        print (\"h_state\",h_state.shape)\n",
    "        #print (\"wh\", self.Wh.shape)\n",
    "        features_dim = self.features_dim\n",
    "\n",
    "        M1 = K.reshape(K.dot(K.reshape(Y_states, (-1, features_dim)), self.Wy),shape = (-1,self.attention_length,features_dim ))\n",
    "        #print(\"here\")\n",
    "        M2 = K.expand_dims(K.dot(h_state, self.Wh),axis=1)\n",
    "        M = K.tanh(M1+M2)\n",
    "        #print(\"here2\")\n",
    "        alpha = K.reshape(K.softmax(K.dot(K.reshape(M, shape = (-1, features_dim)), self.w)), shape = (-1, self.attention_length))\n",
    "        r = tf.squeeze(tf.matmul(tf.transpose(tf.expand_dims(alpha, 2), perm = [0, 2, 1]), Y_states))\n",
    "        h_star = tf.tanh(tf.matmul(r, self.Wp) + tf.matmul(h_state, self.Wx))\n",
    "        \n",
    "\n",
    "        return h_star\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_state (?, 100)\n"
     ]
    }
   ],
   "source": [
    "# Build a sequential model by stacking neural net units \n",
    "#dense layer: simply a layer connect units \n",
    "#dropout layer: for reduce overfitting a regularization methhod\n",
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(input_dim=len(tokenizer.word_index)+1, input_length = MAX_SENT_LEN,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embeddings_matrix], trainable= True, name='word_embedding_layer', \n",
    "                          mask_zero=True)) # trainable=True results in overfitting\n",
    "\n",
    "model_2.add(LSTM(LSTM_DIM, return_sequences=True, name='lstm_layer')) # Can try Bidirectional-LSTM\n",
    "model_2.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.2\n",
    "#model.add(Activation(activation='relu', name='activation_1'))\n",
    "#output (batch_size, timesteps, input_dim)\n",
    "model_2.add(Attention())\n",
    "model_2.add(Dense(4, activation='softmax', name='output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "word_embedding_layer (Embedd (None, 300, 50)           1768800   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 300, 100)          60400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 100)          0         \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 1,869,704\n",
      "Trainable params: 1,869,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001) # Try a different learning rate\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALLBACK FUCTION: TO SAVE MODEL FOR EVERY EPOCH END\n",
    "filepath=\"./result/attention/epoch_40/FNC-1_LSTM_Attention_15Atlength_300_trainable_lr=0.001_{epoch:02d}_{val_acc:.4f}.h5\"\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, \n",
    "                                       monitor='val_acc', \n",
    "                                       verbose=0, \n",
    "                                       save_best_only=True)\n",
    "\n",
    "callbacks_list2 = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60009 samples, validate on 6668 samples\n",
      "Epoch 1/40\n",
      "60009/60009 [==============================] - 189s 3ms/step - loss: 0.4950 - acc: 0.8130 - val_loss: 0.4397 - val_acc: 0.8358\n",
      "Epoch 2/40\n",
      "60009/60009 [==============================] - 189s 3ms/step - loss: 0.4097 - acc: 0.8455 - val_loss: 0.3927 - val_acc: 0.8505\n",
      "Epoch 3/40\n",
      "60009/60009 [==============================] - 189s 3ms/step - loss: 0.3535 - acc: 0.8666 - val_loss: 0.3542 - val_acc: 0.8721\n",
      "Epoch 4/40\n",
      "60009/60009 [==============================] - 189s 3ms/step - loss: 0.3118 - acc: 0.8831 - val_loss: 0.3409 - val_acc: 0.8697\n",
      "Epoch 5/40\n",
      "60009/60009 [==============================] - 189s 3ms/step - loss: 0.2818 - acc: 0.8943 - val_loss: 0.3128 - val_acc: 0.8827\n",
      "Epoch 6/40\n",
      "60009/60009 [==============================] - 189s 3ms/step - loss: 0.2552 - acc: 0.9032 - val_loss: 0.2914 - val_acc: 0.8902\n",
      "Epoch 7/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.2291 - acc: 0.9136 - val_loss: 0.2729 - val_acc: 0.9031\n",
      "Epoch 8/40\n",
      "60009/60009 [==============================] - 189s 3ms/step - loss: 0.2102 - acc: 0.9208 - val_loss: 0.2737 - val_acc: 0.8994\n",
      "Epoch 9/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1943 - acc: 0.9267 - val_loss: 0.2561 - val_acc: 0.9055\n",
      "Epoch 10/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1815 - acc: 0.9311 - val_loss: 0.2471 - val_acc: 0.9112\n",
      "Epoch 11/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1692 - acc: 0.9346 - val_loss: 0.2355 - val_acc: 0.9159\n",
      "Epoch 12/40\n",
      "60009/60009 [==============================] - 195s 3ms/step - loss: 0.1566 - acc: 0.9406 - val_loss: 0.2374 - val_acc: 0.9210\n",
      "Epoch 13/40\n",
      "60009/60009 [==============================] - 198s 3ms/step - loss: 0.1468 - acc: 0.9447 - val_loss: 0.2304 - val_acc: 0.9205\n",
      "Epoch 14/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1395 - acc: 0.9457 - val_loss: 0.2408 - val_acc: 0.9159\n",
      "Epoch 15/40\n",
      "60009/60009 [==============================] - 191s 3ms/step - loss: 0.1307 - acc: 0.9501 - val_loss: 0.2270 - val_acc: 0.9240\n",
      "Epoch 16/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1220 - acc: 0.9529 - val_loss: 0.2297 - val_acc: 0.9258\n",
      "Epoch 17/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1202 - acc: 0.9535 - val_loss: 0.2135 - val_acc: 0.9265\n",
      "Epoch 18/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1096 - acc: 0.9584 - val_loss: 0.2171 - val_acc: 0.9289\n",
      "Epoch 19/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.1028 - acc: 0.9610 - val_loss: 0.2079 - val_acc: 0.9343\n",
      "Epoch 20/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0987 - acc: 0.9633 - val_loss: 0.2038 - val_acc: 0.9381\n",
      "Epoch 21/40\n",
      "60009/60009 [==============================] - 194s 3ms/step - loss: 0.0921 - acc: 0.9644 - val_loss: 0.2121 - val_acc: 0.9324\n",
      "Epoch 22/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0882 - acc: 0.9662 - val_loss: 0.2219 - val_acc: 0.9340\n",
      "Epoch 23/40\n",
      "60009/60009 [==============================] - 192s 3ms/step - loss: 0.0846 - acc: 0.9681 - val_loss: 0.2140 - val_acc: 0.9366\n",
      "Epoch 24/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0791 - acc: 0.9704 - val_loss: 0.2119 - val_acc: 0.9387\n",
      "Epoch 25/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0775 - acc: 0.9706 - val_loss: 0.2075 - val_acc: 0.9400\n",
      "Epoch 26/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0746 - acc: 0.9726 - val_loss: 0.2330 - val_acc: 0.9379\n",
      "Epoch 27/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0705 - acc: 0.9741 - val_loss: 0.2257 - val_acc: 0.9402\n",
      "Epoch 28/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0658 - acc: 0.9765 - val_loss: 0.2173 - val_acc: 0.9399\n",
      "Epoch 29/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0613 - acc: 0.9770 - val_loss: 0.2299 - val_acc: 0.9417\n",
      "Epoch 30/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0597 - acc: 0.9781 - val_loss: 0.2310 - val_acc: 0.9450\n",
      "Epoch 31/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0604 - acc: 0.9785 - val_loss: 0.2051 - val_acc: 0.9474\n",
      "Epoch 32/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0535 - acc: 0.9815 - val_loss: 0.2223 - val_acc: 0.9421\n",
      "Epoch 33/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0516 - acc: 0.9815 - val_loss: 0.2247 - val_acc: 0.9465\n",
      "Epoch 34/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0480 - acc: 0.9830 - val_loss: 0.2294 - val_acc: 0.9451\n",
      "Epoch 35/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0463 - acc: 0.9831 - val_loss: 0.2223 - val_acc: 0.9466\n",
      "Epoch 36/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0479 - acc: 0.9836 - val_loss: 0.2349 - val_acc: 0.9460\n",
      "Epoch 37/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0455 - acc: 0.9844 - val_loss: 0.2181 - val_acc: 0.9474\n",
      "Epoch 38/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0452 - acc: 0.9845 - val_loss: 0.2310 - val_acc: 0.9471\n",
      "Epoch 39/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0406 - acc: 0.9859 - val_loss: 0.2751 - val_acc: 0.9396\n",
      "Epoch 40/40\n",
      "60009/60009 [==============================] - 190s 3ms/step - loss: 0.0400 - acc: 0.9859 - val_loss: 0.2267 - val_acc: 0.9477\n"
     ]
    }
   ],
   "source": [
    "#%%capture history_12\n",
    "# history1 = model_1.fit(X_train, y_train,\n",
    "#           batch_size=BATCH_SIZE,\n",
    "#           epochs=N_EPOCHS,\n",
    "#           validation_data=(X_vali, y_vali),\n",
    "#           callbacks = callbacks_list1)\n",
    "history2 = model_2.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=N_EPOCHS,\n",
    "          validation_data=(X_vali, y_vali),\n",
    "          callbacks = callbacks_list2)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f91af16dda0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
